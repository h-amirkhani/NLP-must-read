### Annotation-Artifacts (2018)
- [Annotation Artifacts in Natural Language Inference Data](http://aclweb.org/anthology/N18-2017) . Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel R. Bowman, Noah A. Smith .  NAACL-HLT, 2018.
- It shows that because of the heuristics used by annotators, large-scale datasets for natural language inference contain clues which are exploited by the learning algorithms, resulting in the models which “game” the task by learning to detect annotation artifacts instead of learning to inference.

### SNLI (2015)
- [A large annotated corpus for learning natural language inference](https://arxiv.org/pdf/1508.05326.pdf) . Samuel R. Bowman, Gabor Angeli, Christopher Potts, D. Christopher Manning . EMNLP, 2015.
- A dataset containing 570k sentence-pairs labeled as entailment, contradiction, and neutral. This dataset raised tremendous interest in the NLI task, and many end-to-end neural models were developed, achieving promising results.
- Useful resources:
  - [SNLI leaderboard](https://nlp.stanford.edu/projects/snli/)
